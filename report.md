# Research Report

## Objective
hallucination mitigation in large language models

## INPUT_GROUNDING
Input grounding and context alignment related to hallucination mitigation in large language models

### Top Papers
- 2025 | [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915v1) — [PDF](https://arxiv.org/pdf/2507.22915v1.pdf)
- 2024 | [Mitigating Multilingual Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2408.00550v1) — [PDF](https://arxiv.org/pdf/2408.00550v1.pdf)
- 2025 | [Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization](https://arxiv.org/abs/2501.17295v1) — [PDF](https://arxiv.org/pdf/2501.17295v1.pdf)

### Gaps
- Concept underrepresented or missing: dataset

## REASONING
Reasoning and inference mechanisms related to hallucination mitigation in large language models

### Top Papers
- 2025 | [Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems](https://arxiv.org/abs/2510.24476v1) — [PDF](https://arxiv.org/pdf/2510.24476v1.pdf)
- 2025 | [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915v1) — [PDF](https://arxiv.org/pdf/2507.22915v1.pdf)
- 2024 | [A Unified Hallucination Mitigation Framework for Large Vision-Language Models](https://arxiv.org/abs/2409.16494v1) — [PDF](https://arxiv.org/pdf/2409.16494v1.pdf)

### Gaps
- Concept underrepresented or missing: dataset

## GENERATION
Text generation behavior and decoding strategies related to hallucination mitigation in large language models

### Top Papers
- 2025 | [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915v1) — [PDF](https://arxiv.org/pdf/2507.22915v1.pdf)
- 2024 | [THaMES: An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models](https://arxiv.org/abs/2409.11353v3) — [PDF](https://arxiv.org/pdf/2409.11353v3.pdf)
- 2024 | [Generation Constraint Scaling Can Mitigate Hallucination](https://arxiv.org/abs/2407.16908v1) — [PDF](https://arxiv.org/pdf/2407.16908v1.pdf)

## EVALUATION
Evaluation methods and benchmarks related to hallucination mitigation in large language models

### Top Papers
- 2023 | [Evaluation and Analysis of Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2308.15126v3) — [PDF](https://arxiv.org/pdf/2308.15126v3.pdf)
- 2025 | [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915v1) — [PDF](https://arxiv.org/pdf/2507.22915v1.pdf)
- 2023 | [LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2306.09265v1) — [PDF](https://arxiv.org/pdf/2306.09265v1.pdf)

## SAFETY
Safety, robustness, and verification related to hallucination mitigation in large language models

### Top Papers
- 2025 | [Safety at Scale: A Comprehensive Survey of Large Model and Agent Safety](https://arxiv.org/abs/2502.05206v5) — [PDF](https://arxiv.org/pdf/2502.05206v5.pdf)
- 2025 | [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915v1) — [PDF](https://arxiv.org/pdf/2507.22915v1.pdf)
- 2025 | [Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization](https://arxiv.org/abs/2501.17295v1) — [PDF](https://arxiv.org/pdf/2501.17295v1.pdf)

